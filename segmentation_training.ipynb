{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mount tới Google Drive"
      ],
      "metadata": {
        "id": "3r0npA7GsIa8"
      },
      "id": "3r0npA7GsIa8"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/MAP_ROAD/"
      ],
      "metadata": {
        "id": "SVufMTbMsF3Y"
      },
      "id": "SVufMTbMsF3Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8375c6d7",
      "metadata": {
        "id": "8375c6d7"
      },
      "source": [
        "# Import thư viện cần thiết"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "744be81e",
      "metadata": {
        "id": "744be81e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "from datetime import datetime\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17db7387",
      "metadata": {
        "id": "17db7387"
      },
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "0ecc3cb9",
      "metadata": {
        "id": "0ecc3cb9"
      },
      "outputs": [],
      "source": [
        "\n",
        "TQDM_BAR_FORMAT = '{l_bar}{bar:10}{r_bar}'  # Cần thiết cho tqdm\n",
        "\n",
        "# DATASET\n",
        "images_file = 'data/images' # Tập chứa ảnh training\n",
        "segs_file = 'data/labels'  # Tập chứa label của ảnh training\n",
        "test_file = 'data/test'   # Tập chứa ảnh test\n",
        "save_dir = 'train_val'   # Path lưu kết quả của tập test\n",
        "ckpt_file = \"best.pt\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "val_size = 0.1          # Tỷ lệ chia tập val\n",
        "\n",
        "# AUGMENTATION\n",
        "augmentation = True   # True nếu muốn tăng cường dữ liệu\n",
        "ColorJitter = True\n",
        "Rotate = True\n",
        "GridDistortion = True\n",
        "\n",
        "# TRAINING\n",
        "lr = 5e-2         # learning rate\n",
        "num_epochs = 35  # Số lượng epoch training\n",
        "batch_size = 16   # Batch size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8164a5df",
      "metadata": {
        "id": "8164a5df"
      },
      "source": [
        "# Chuẩn bị dữ liệu (Data Loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "421be6dd",
      "metadata": {
        "id": "421be6dd"
      },
      "outputs": [],
      "source": [
        "class CustomDataLoader(Dataset):\n",
        "    def __init__(self, data,\n",
        "                     images_file,\n",
        "                     segs_file,\n",
        "                     is_val,\n",
        "                     augmentation=False,\n",
        "                     ColorJitter=False,\n",
        "                     Rotate=False,\n",
        "                     GridDistortion=False):\n",
        "\n",
        "        self.ims_file = data\n",
        "        self.images_file = images_file\n",
        "        self.segs_file = segs_file\n",
        "\n",
        "        self.Tensor = transforms.ToTensor()\n",
        "\n",
        "        if is_val:\n",
        "            self.aug = [False, ColorJitter, Rotate, GridDistortion]\n",
        "        else:\n",
        "            self.aug = [augmentation, ColorJitter, Rotate, GridDistortion]\n",
        "\n",
        "        self.do_aug = [A.ColorJitter(brightness=0.3, contrast=0.2, saturation=0.2, hue=0.2, always_apply=False, p=0.4), A.Rotate(limit=15, p=0.3), A.GridDistortion(p=0.3)]\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.ims_file))\n",
        "\n",
        "    def img2seg(self, path):\n",
        "        return path.replace(self.images_file, self.segs_file).replace('.jpg', '.png')\n",
        "\n",
        "\n",
        "    def preprocess(self, img, seg):\n",
        "        h0, w0 = img.shape[:2]\n",
        "\n",
        "        img = cv2.resize(img, (160, 80), interpolation = cv2.INTER_LINEAR)\n",
        "        seg = cv2.resize(seg, (160, 80), interpolation = cv2.INTER_LINEAR)\n",
        "\n",
        "        img = img/255\n",
        "        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "        img = np.ascontiguousarray(img)  # contiguous\n",
        "\n",
        "        seg = seg/255\n",
        "        seg = seg.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "        seg = np.ascontiguousarray(seg)  # contiguous\n",
        "\n",
        "        return img, seg\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        img = cv2.imread(self.ims_file[index])\n",
        "        seg = cv2.imread(self.img2seg(self.ims_file[index]))\n",
        "\n",
        "\n",
        "        if self.aug[0]:\n",
        "            img_pre, seg_pre = self.preprocess(img, seg)\n",
        "            img_out, seg_out = [torch.from_numpy(img_pre)], [seg_pre]\n",
        "            for i, f in enumerate(self.do_aug):\n",
        "                if self.aug[i+1]:\n",
        "                    au = f(image=img, mask=seg)\n",
        "                    img_aug, seg_aug = au['image'], au['mask']\n",
        "\n",
        "                    img_aug, seg_aug = self.preprocess(img_aug, seg_aug)\n",
        "\n",
        "                    img_out.append(torch.from_numpy(img_aug))\n",
        "                    seg_out.append(torch.from_numpy(seg_aug))\n",
        "\n",
        "            return img_out, seg_out\n",
        "\n",
        "        else:\n",
        "            img_pre, seg_pre = self.preprocess(img, seg)\n",
        "            img_out, seg_out = [torch.from_numpy(img_pre)], [torch.from_numpy(seg_pre)]\n",
        "\n",
        "            return img_out, seg_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "0dd52362",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dd52362",
        "outputId": "da86868f-874c-4d8e-f9de-47b1fb9bf0af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading data: 100%|██████████| 317/317 [00:00<00:00, 611588.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training size: 285\n",
            "Val size: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def split_data(images_file, segs_file, val_size):\n",
        "    pbar = tqdm(os.listdir(images_file), total=len(os.listdir(images_file)), desc='Loading data', bar_format=TQDM_BAR_FORMAT)\n",
        "    f = []\n",
        "    for name in pbar:\n",
        "        f.append(os.path.join(images_file, name))\n",
        "\n",
        "    train, val = train_test_split(f, test_size=val_size, train_size=(1-val_size))\n",
        "\n",
        "    return train, val\n",
        "\n",
        "train, val = split_data(images_file, segs_file, val_size)\n",
        "\n",
        "train_dataset = CustomDataLoader(train,\n",
        "                                 images_file,\n",
        "                                 segs_file,\n",
        "                                 is_val=False,\n",
        "                                 augmentation=augmentation,\n",
        "                                 ColorJitter=ColorJitter,\n",
        "                                 Rotate=Rotate,\n",
        "                                 GridDistortion=GridDistortion)\n",
        "\n",
        "val_dataset = CustomDataLoader(val,\n",
        "                               images_file,\n",
        "                               segs_file,\n",
        "                               is_val=True,\n",
        "                               augmentation=augmentation,\n",
        "                               ColorJitter=ColorJitter,\n",
        "                               Rotate=Rotate,\n",
        "                               GridDistortion=GridDistortion)\n",
        "\n",
        "print(f'Training size: {len(train_dataset)}')\n",
        "print(f'Val size: {len(val_dataset)}')\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, pin_memory=True, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, pin_memory=True, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89aea99d",
      "metadata": {
        "id": "89aea99d"
      },
      "source": [
        "# Khởi tạo Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "a0f81d14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0f81d14",
        "outputId": "49d0432c-a735-4af6-e3ac-84c4bb11ff37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input size: torch.Size([1, 3, 80, 160])\n",
            "Total params: 144433\n"
          ]
        }
      ],
      "source": [
        "def double_conv(in_ch, out_ch):\n",
        "    conv_op = nn.Sequential(\n",
        "        nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(out_ch),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(out_ch),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "    return conv_op\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_ch=3, out_ch=1):\n",
        "        super(UNet, self).__init__()\n",
        "        self.conv1 = double_conv(in_ch, 8)\n",
        "        self.conv2 = double_conv(8, 16)\n",
        "        self.conv3 = double_conv(16, 32)\n",
        "        self.conv4 = double_conv(32, 64)\n",
        "\n",
        "        self.conv5 = double_conv(96, 32)\n",
        "        self.conv6 = double_conv(48, 16)\n",
        "        self.conv7 = double_conv(24, 8)\n",
        "        self.pooling = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.upsample1 = nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=2, stride=2)\n",
        "        self.upsample2 = nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=2, stride=2)\n",
        "        self.upsample3 = nn.ConvTranspose2d(in_channels=16, out_channels=16, kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv0 = nn.Conv2d(in_channels=8, out_channels=out_ch, kernel_size=1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        #Encoder\n",
        "        down1 = self.conv1(x)\n",
        "        pool1 = self.pooling(down1)\n",
        "        down2 = self.conv2(pool1)\n",
        "        pool2 = self.pooling(down2)\n",
        "        down3 = self.conv3(pool2)\n",
        "        pool3 = self.pooling(down3)\n",
        "        down4 = self.conv4(pool3)\n",
        "\n",
        "        #Decoder\n",
        "        upsample1 = self.upsample1(down4)\n",
        "        cat1 = torch.cat([down3, upsample1], dim=1)\n",
        "        up1 = self.conv5(cat1)\n",
        "        upsample2 = self.upsample2(up1)\n",
        "        cat2 = torch.cat([down2, upsample2], dim=1)\n",
        "        up2 = self.conv6(cat2)\n",
        "        upsample3 = self.upsample3(up2)\n",
        "        cat3 = torch.cat([down1, upsample3], dim=1)\n",
        "        up3 = self.conv7(cat3)\n",
        "\n",
        "        outputs = self.conv0(up3)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "img = torch.rand(1, 3, 80, 160)\n",
        "model = UNet()\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "print(f'Input size: {img.size()}')\n",
        "print(f'Total params: {total_params}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90fd3cf0",
      "metadata": {
        "id": "90fd3cf0"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "5a3c6832",
      "metadata": {
        "id": "5a3c6832"
      },
      "outputs": [],
      "source": [
        "def dice_loss(input: torch.Tensor, target: torch.Tensor, reduce_batch_first: bool = False, epsilon: float = 1e-6):\n",
        "    # Average of Dice coefficient for all batches, or for a single mask\n",
        "#     assert input.size() == target.size()\n",
        "#     assert input.dim() == 3 or not reduce_batch_first\n",
        "\n",
        "#     sum_dim = (-1, -2) if input.dim() == 2 or not reduce_batch_first else (-1, -2, -3)\n",
        "\n",
        "#     print(input.size())\n",
        "#     print(target.size())\n",
        "    inter = 2 * (input * target)\n",
        "    sets_sum = input + target\n",
        "    sets_sum = torch.where(sets_sum == 0, inter, sets_sum)\n",
        "\n",
        "    dice = (inter + epsilon) / (sets_sum + epsilon)\n",
        "    return 1.0 - dice.mean()\n",
        "\n",
        "\n",
        "def poly_lr_scheduler(lr, max_epochs, optimizer, epoch, power=2):\n",
        "    lr = round(lr * (1 - epoch / max_epochs) ** power, 8)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "    return lr\n",
        "\n",
        "\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    num_val_batches = len(val_loader)\n",
        "    dice_score = 0\n",
        "\n",
        "    for i, (img_l, target_l) in enumerate(val_loader):\n",
        "\n",
        "        for img, target in zip(img_l, target_l):\n",
        "            img = img.to(device).float()\n",
        "            true_masks = target.to(device).float()\n",
        "            true_masks = torch.mean(true_masks, dim=1, keepdim=True)\n",
        "            mask_pred = model(img)\n",
        "            mask_pred = (torch.sigmoid(mask_pred) > 0.5).float()\n",
        "\n",
        "\n",
        "            dice_score += dice_loss(mask_pred, true_masks, reduce_batch_first=False)\n",
        "\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    return dice_score / max(num_val_batches, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "8c359ccd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8c359ccd",
        "outputId": "2bbabe51-8014-435c-e434-636b728a2c96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch       Loss      Score         Lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "         0/34       0.7488       0.1007         0.05: 100%|██████████| 18/18 [00:48<00:00,  2.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch       Loss      Score         Lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "         1/34       0.7394       0.4364      0.04718: 100%|██████████| 18/18 [00:51<00:00,  2.87s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch       Loss      Score         Lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "         2/34       0.1925       0.1062      0.04195: 100%|██████████| 18/18 [00:47<00:00,  2.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch       Loss      Score         Lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "         3/34       0.1723       0.0525      0.03506: 100%|██████████| 18/18 [00:49<00:00,  2.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch       Loss      Score         Lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "         4/34       0.1265       0.1475      0.02751: 100%|██████████| 18/18 [00:47<00:00,  2.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch       Loss      Score         Lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "         5/34       0.1108       0.0394      0.02021: 100%|██████████| 18/18 [00:51<00:00,  2.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch       Loss      Score         Lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "         6/34      0.07909      0.02515      0.01387: 100%|██████████| 18/18 [00:49<00:00,  2.74s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch       Loss      Score         Lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "         7/34       0.1073      0.03489     0.008879: 100%|██████████| 18/18 [00:48<00:00,  2.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch       Loss      Score         Lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "         8/34      0.08564      0.01844     0.005284: 100%|██████████| 18/18 [00:47<00:00,  2.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch       Loss      Score         Lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "         9/34       0.1185      0.01579     0.002916: 100%|██████████| 18/18 [00:48<00:00,  2.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch       Loss      Score         Lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        10/34      0.08937      0.01344     0.001488: 100%|██████████| 18/18 [00:50<00:00,  2.83s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch       Loss      Score         Lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        11/34      0.07414      0.01412    0.0006995: 100%|██████████| 18/18 [00:47<00:00,  2.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch       Loss      Score         Lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        12/34      0.05401      0.01402    0.0003021:  61%|██████    | 11/18 [00:32<00:20,  2.93s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-365e69f84f64>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m                                      (f'{epoch}/{num_epochs - 1}', last, dice_score, lr))\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mdice_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlast\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-3af7f31846dc>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, val_loader)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mdice_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_l\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-ba7ab20ee45a>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mims_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg2seg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mims_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr, (0.9, 0.999), eps=1e-08, weight_decay=5e-4)\n",
        "model = model.to(device)\n",
        "\n",
        "best = 10000\n",
        "dice_score = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    poly_lr_scheduler(lr, num_epochs, optimizer, epoch)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        lr = param_group['lr']\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    print(('\\n' + '%11s' * 4) % ('Epoch', 'Loss', 'Score', 'Lr'))\n",
        "    pbar = enumerate(train_loader)\n",
        "    total_batch = len(train_loader)\n",
        "    pbar = tqdm(pbar, total=total_batch, bar_format=TQDM_BAR_FORMAT)\n",
        "\n",
        "    for i, (img_l, target_l) in pbar:\n",
        "        for img, target in zip(img_l, target_l):\n",
        "            img = img.to(device).float()\n",
        "            true_masks = target.to(device).float()\n",
        "            true_masks = torch.mean(true_masks, dim=1, keepdim=True)\n",
        "            mask_pred = model(img)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(mask_pred, true_masks)\n",
        "            loss += dice_loss(torch.sigmoid(mask_pred), true_masks, reduce_batch_first=True)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            last = loss.item()\n",
        "\n",
        "            pbar.set_description(('%13s' * 1 + '%13.4g'*3) %\n",
        "                                     (f'{epoch}/{num_epochs - 1}', last, dice_score, lr))\n",
        "\n",
        "            dice_score = evaluate(model, val_loader)\n",
        "\n",
        "            if last < best:\n",
        "                best = last\n",
        "\n",
        "            ckpt = {\n",
        "                    'epoch': epoch,\n",
        "                    'state_dict': model.state_dict(),\n",
        "                    'optimizer': optimizer.state_dict(),\n",
        "                    'loss': best,\n",
        "                    'dice_score': dice_score,\n",
        "                    'date': datetime.now().isoformat()\n",
        "            }\n",
        "\n",
        "            torch.save(ckpt, ckpt_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c3c9419",
      "metadata": {
        "id": "3c3c9419"
      },
      "source": [
        "# Đánh giá với dữ liệu test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "27f2b297",
      "metadata": {
        "id": "27f2b297"
      },
      "outputs": [],
      "source": [
        "model = UNet()\n",
        "checkpoint = torch.load(ckpt_file)\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "images = os.listdir(test_file)\n",
        "\n",
        "for name in images:\n",
        "    img = cv2.imread(os.path.join(test_file, name))\n",
        "    img = cv2.resize(img, (160, 80), interpolation = cv2.INTER_LINEAR)\n",
        "\n",
        "    img = img/255\n",
        "    img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
        "    img = np.ascontiguousarray(img)  # contiguous\n",
        "\n",
        "    img = torch.from_numpy(img)\n",
        "    img = img.to(device).unsqueeze(0).float()\n",
        "\n",
        "#     print(img.shape)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mask_pred = model(img)\n",
        "\n",
        "    mask_pred = (torch.sigmoid(mask_pred) > 0.5).float()\n",
        "    to_save = mask_pred.squeeze(0).squeeze(0)\n",
        "    to_save = (to_save.cpu().numpy()*255).astype(np.uint8)\n",
        "\n",
        "    save = f'train_val/{name}.jpg'\n",
        "    cv2.imwrite(save, to_save)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "REMviVqIbksk"
      },
      "id": "REMviVqIbksk",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}